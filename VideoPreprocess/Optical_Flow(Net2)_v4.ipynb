{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Optical Flow(Net2)_v4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PJQFqCRjTLOH",
        "gqOOObJXTxXm",
        "wvDsACj1VsGD",
        "eNZu8rfTWRtk",
        "BaX6wbjS5nRY",
        "3LpIrCby5s_N",
        "xgmxymDL6Plj",
        "2IQiY4VISh0F"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVN9kQ-Ifj-t",
        "outputId": "b67325f4-5c68-4918-936c-c8145222677f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJQFqCRjTLOH"
      },
      "source": [
        "# Convert panoramic videos to perspective videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqOOObJXTxXm"
      },
      "source": [
        "#### Make folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzU4q3vMR3RP"
      },
      "source": [
        "import os\n",
        "def mkdir_ifnotexists(dir):\n",
        "    if os.path.exists(dir):\n",
        "        return\n",
        "    os.mkdir(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLy-YMQYUUim"
      },
      "source": [
        "## Convert panoramic view to perspective view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--8seiT3VLCU"
      },
      "source": [
        "###Frame processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvDsACj1VsGD"
      },
      "source": [
        "####Split up-down stereo image into left eye and right eye"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nAe7ZaOVKhC"
      },
      "source": [
        "import cv2 as cv \n",
        "import numpy as np \n",
        "\n",
        "def image_split(img):\n",
        "    left = img[0:int(img.shape[0]/2)]\n",
        "    right = img[int(img.shape[0]/2):int(img.shape[0])]\n",
        "    return left, right"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNZu8rfTWRtk"
      },
      "source": [
        "###Convert panoramic image to perspective image based on view position"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCB8mvM_WheS"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "class Equirec2Perspec:\n",
        "    # _init_ function\n",
        "    # Input: 1. img: current frame of the panoramic video\n",
        "    def __init__(self, img):\n",
        "        self._img = img\n",
        "        [self._height, self._width, _] = self._img.shape\n",
        "    \n",
        "    # Function convert equirectangular image to perspective\n",
        "    # view based on the view position.\n",
        "    # Input: \n",
        "    # 1. wFOV: horizontal field of view in degrees\n",
        "    # 2. THETA: left/right angle in degrees of view center(right direction is positive, left direction is negative)\n",
        "    # 3. PHI: up/down angle in degrees of view center(up direction is positive, down direction is negative)\n",
        "    # 4. height, width: height/width of the output viewport image, should fit the resolution of each eye's viewport\n",
        "    def GetPerspective(self, FOV, THETA, PHI, height, width):\n",
        "        # set radius for the sphere which \n",
        "        # the equirectangular image is wrapped to\n",
        "        RADIUS = 1\n",
        "        \n",
        "        # height, width of the input frame\n",
        "        equ_h = self._height\n",
        "        equ_w = self._width\n",
        "\n",
        "        # center of the input frame\n",
        "        equ_cx = (equ_w - 1) / 2.0\n",
        "        equ_cy = (equ_h - 1) / 2.0\n",
        "\n",
        "        # set vertical field of view based \n",
        "        # on output image size and horizontal \n",
        "        # field of view\n",
        "        wFOV = FOV\n",
        "        hFOV = float(height) / width * wFOV\n",
        "        \n",
        "        # center of the output image\n",
        "        c_x = (width - 1) / 2.0\n",
        "        c_y = (height - 1) / 2.0\n",
        "\n",
        "        # horizontal length of view:\n",
        "        # w_len = 2 * radius * tan(wFOV/2)\n",
        "        w_len = 2 * RADIUS * np.tan(np.radians(wFOV / 2.0))\n",
        "        # each pixels from frame represents \n",
        "        # how many units of the horizontal length of view\n",
        "        w_interval = w_len / (width - 1)\n",
        "\n",
        "        # same precedure for viertical view\n",
        "        h_len = 2 * RADIUS * np.tan(np.radians(hFOV / 2.0)) \n",
        "        h_interval = h_len / (height - 1)\n",
        "        \n",
        "        # x_map: radius, distance between the viewport to the sphere center\n",
        "        # y_map: horizontal distance between each image pixel and image center\n",
        "        # z_map: vertical distance between each image pixel and image center\n",
        "        x_map = np.zeros([height, width], np.float32) + RADIUS\n",
        "        y_map = np.tile((np.arange(0, width) - c_x) * w_interval, [height, 1])\n",
        "        z_map = -np.tile((np.arange(0, height) - c_y) * h_interval, [width, 1]).T\n",
        "        # distance between the sphere center and each pixel at viewport image\\\n",
        "        # D = sqrt(radius^2 + horizontal_distance^2 + vertical_distance^2)\n",
        "        D = np.sqrt(x_map**2 + y_map**2 + z_map**2)\n",
        "        xyz = np.zeros([height, width, 3], np.float)\n",
        "        # normalize to the sphere that equirectangular image is wrapped to\n",
        "        xyz[:, :, 0] = (RADIUS / D * x_map)[:, :]\n",
        "        xyz[:, :, 1] = (RADIUS / D * y_map)[:, :]\n",
        "        xyz[:, :, 2] = (RADIUS / D * z_map)[:, :]\n",
        "        \n",
        "        # unit vector along vertical rotation axis\n",
        "        vertical_axis = np.array([0.0, 1.0, 0.0], np.float32)\n",
        "        # unit vector along horizontal rotation axis\n",
        "        horizontal_axis = np.array([0.0, 0.0, 1.0], np.float32)\n",
        "        # Rodrigues' rotation formula\n",
        "        [R1, _] = cv2.Rodrigues(horizontal_axis * np.radians(THETA))\n",
        "        [R2, _] = cv2.Rodrigues(np.dot(R1, vertical_axis) * np.radians(-PHI))\n",
        "\n",
        "        # rotate the viewport\n",
        "        xyz = xyz.reshape([height * width, 3]).T\n",
        "        xyz = np.dot(R1, xyz)\n",
        "        xyz = np.dot(R2, xyz).T\n",
        "        # convert distance to latitude and longitude\n",
        "        lat = np.arcsin(xyz[:, 2] / RADIUS)\n",
        "        lon = np.zeros([height * width], np.float)\n",
        "        theta = np.arctan(xyz[:, 1] / xyz[:, 0])\n",
        "        \n",
        "        # mask to crop out the subimages from equirectangular image\n",
        "        idx1 = xyz[:, 0] > 0\n",
        "        idx2 = xyz[:, 1] > 0\n",
        "\n",
        "        idx3 = ((1 - idx1) * idx2).astype(np.bool)\n",
        "        idx4 = ((1 - idx1) * (1 - idx2)).astype(np.bool)\n",
        "        \n",
        "        lon[idx1] = theta[idx1]\n",
        "        lon[idx3] = theta[idx3] + np.pi\n",
        "        lon[idx4] = theta[idx4] - np.pi\n",
        "\n",
        "        # cooridinates of the mask at equirectangular image, in pixels\n",
        "        lon = lon.reshape([height, width]) / np.pi * 180\n",
        "        lat = -lat.reshape([height, width]) / np.pi * 180\n",
        "        lon = lon / 180 * equ_cx + equ_cx\n",
        "        lat = lat / 90 * equ_cy + equ_cy\n",
        "        \n",
        "        # sample equirectangular image based on coordinates\n",
        "        persp = cv2.remap(self._img, lon.astype(np.float32), lat.astype(np.float32), cv2.INTER_CUBIC, borderMode=cv2.BORDER_WRAP)\n",
        "        return lon.astype(np.int), lat.astype(np.int),persp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n39IAd4_j47h"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import cv2 as cv\n",
        "import csv\n",
        "from numpy import save\n",
        "\n",
        "def perspectiveSotre(lon, lat, videoName):\n",
        "  frame_pth='./frames/'\n",
        "  mkdir_ifnotexists(frame_pth)\n",
        "  path = './videos/'+videoName+'.mp4'\n",
        "  # DEPTH_VISUALIZATION_SCALE = 2048\n",
        "  # The video feed is read in as \n",
        "  # a VideoCapture object \n",
        "  cap = cv.VideoCapture(str(path)) \n",
        "  \n",
        "  # ret = a boolean return value from \n",
        "  # getting the frame, first_frame = the \n",
        "  # first frame in the entire video sequence \n",
        "  ret, first_frame = cap.read() \n",
        "\n",
        "\n",
        "  first_left = image_split(first_frame)[0]\n",
        "  first_left_pers = Equirec2Perspec(first_left)\n",
        "  [_, _, first_left_pers] = first_left_pers.GetPerspective(88, lon, lat, 1440, 1600)\n",
        "  cv.imwrite(frame_pth+'frame_'+\n",
        "              '{0:0=6d}'.format(int(cap.get(cv.CAP_PROP_POS_FRAMES)))+'.png', first_left_pers)\n",
        "\n",
        "\n",
        "  # Creates an image filled with zero \n",
        "  # intensities with the same dimensions  \n",
        "  # as the frame \n",
        "  mask = np.zeros_like(first_left_pers) \n",
        "      \n",
        "  # Sets image saturation to maximum \n",
        "  mask[..., 1] = 255        \n",
        "\n",
        "\n",
        "  n = 0\n",
        "\n",
        "  while(cap.isOpened()): \n",
        "    print(cap.get(cv.CAP_PROP_POS_FRAMES))\n",
        "    ret, frame = cap.read() \n",
        "    if ret == False:\n",
        "      break\n",
        "        \n",
        "    # Image per eye\n",
        "    left_img = image_split(frame)[0]\n",
        "    left_img = Equirec2Perspec(left_img)\n",
        "    [_, _, left_img] = left_img.GetPerspective(107, lon, lat, 1440, 1600)\n",
        "    frame = left_img\n",
        "    cv.imwrite(frame_pth+'frame_'+\n",
        "              '{0:0=6d}'.format(int(cap.get(cv.CAP_PROP_POS_FRAMES)))+'.png', left_img)\n",
        "\n",
        "    n = n +1\n",
        "    \n",
        "  # The following frees up resources and \n",
        "  # closes all windows \n",
        "  cap.release()\n",
        "  cv.destroyAllWindows() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaX6wbjS5nRY"
      },
      "source": [
        "# Setup and Install FlowNet2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LpIrCby5s_N"
      },
      "source": [
        "## Download compatible Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GND8lAHT5oYm",
        "outputId": "c0233c70-4500-4f7e-9696-0cb88b57e77e"
      },
      "source": [
        "!pip install torch==1.0.0 torchvision==0.2.2 -f https://download.pytorch.org/whl/cu90/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu90/torch_stable.html\n",
            "Collecting torch==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/3b/0b8de6e654c2983898564226792c6f09d9bcaba97b7b29c40e4ed4ae43ed/torch-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K     |████████████████████████████████| 591.8MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/a1/66d72a2fe580a9f0fcbaaa5b976911fbbde9dce9b330ba12791997b856e9/torchvision-0.2.2-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n",
            "\u001b[?25hCollecting tqdm==4.19.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/c4/b67cf1ab472b770e08e94105a0c7ca7032cd070627c435f5998c9cf6e64f/tqdm-4.19.9-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, tqdm, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.0.0 torchvision-0.2.2 tqdm-4.19.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd7VG0965xKF"
      },
      "source": [
        "## Download and setup FlowNet2 files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4SYLm3P50M-",
        "outputId": "0625fb19-32c4-4237-9af5-871f803288ff"
      },
      "source": [
        "import os\n",
        "# get flownet2-pytorch source\n",
        "#!git clone https://github.com/Gauravv97/flownet2-pytorch.git\n",
        "!git clone https://github.com/NVIDIA/flownet2-pytorch.git\n",
        "!mv /content/flownet2-pytorch /content/flownet2pytorch\n",
        "os.chdir('./flownet2pytorch')\n",
        "# install custom layers\n",
        "!bash install.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'flownet2-pytorch'...\n",
            "remote: Enumerating objects: 557, done.\u001b[K\n",
            "remote: Total 557 (delta 0), reused 0 (delta 0), pack-reused 557\u001b[K\n",
            "Receiving objects: 100% (557/557), 6.28 MiB | 21.80 MiB/s, done.\n",
            "Resolving deltas: 100% (312/312), done.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating correlation_cuda.egg-info\n",
            "writing correlation_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to correlation_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to correlation_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'correlation_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c correlation_cuda.cc -o build/temp.linux-x86_64-3.7/correlation_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=correlation_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kcorrelation_cuda.cc:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c correlation_cuda_kernel.cu -o build/temp.linux-x86_64-3.7/correlation_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=correlation_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/correlation_cuda.o build/temp.linux-x86_64-3.7/correlation_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/correlation_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/correlation_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for correlation_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/correlation_cuda.py to correlation_cuda.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.correlation_cuda.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/correlation_cuda-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing correlation_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.7/site-packages/correlation_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Extracting correlation_cuda-0.0.0-py3.7-linux-x86_64.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding correlation-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/correlation_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for correlation-cuda==0.0.0\n",
            "Finished processing dependencies for correlation-cuda==0.0.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating resample2d_cuda.egg-info\n",
            "writing resample2d_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to resample2d_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to resample2d_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'resample2d_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c resample2d_cuda.cc -o build/temp.linux-x86_64-3.7/resample2d_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kresample2d_cuda.cc:2:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c resample2d_kernel.cu -o build/temp.linux-x86_64-3.7/resample2d_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/resample2d_cuda.o build/temp.linux-x86_64-3.7/resample2d_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/resample2d_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/resample2d_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for resample2d_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resample2d_cuda.py to resample2d_cuda.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.resample2d_cuda.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.7/site-packages/resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Extracting resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding resample2d-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for resample2d-cuda==0.0.0\n",
            "Finished processing dependencies for resample2d-cuda==0.0.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating channelnorm_cuda.egg-info\n",
            "writing channelnorm_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to channelnorm_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to channelnorm_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'channelnorm_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c channelnorm_cuda.cc -o build/temp.linux-x86_64-3.7/channelnorm_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=channelnorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kchannelnorm_cuda.cc:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c channelnorm_kernel.cu -o build/temp.linux-x86_64-3.7/channelnorm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=channelnorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/channelnorm_cuda.o build/temp.linux-x86_64-3.7/channelnorm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/channelnorm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/channelnorm_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for channelnorm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/channelnorm_cuda.py to channelnorm_cuda.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.channelnorm_cuda.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.7/site-packages/channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Extracting channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding channelnorm-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for channelnorm-cuda==0.0.0\n",
            "Finished processing dependencies for channelnorm-cuda==0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKEijRzj6H8M"
      },
      "source": [
        "### Add packages to IPython system path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aYlduR96IlP"
      },
      "source": [
        "import os\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append( '/root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgmxymDL6Plj"
      },
      "source": [
        "# Download files and Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ooGzoaG6QEM",
        "outputId": "938a1f7c-8f6b-4545-fba9-054019cc457f"
      },
      "source": [
        "!pip install pypng\n",
        "!pip install tensorboardx\n",
        "!pip install  setproctitle colorama scipy==1.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pypng\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
            "\r\u001b[K     |▌                               | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 21.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 11.0MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 143kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 163kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 184kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 204kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 225kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 245kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 256kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 266kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 276kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 286kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 296kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 307kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 317kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 327kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 337kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 348kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 358kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 368kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 378kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 389kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 399kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 409kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 419kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 430kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 440kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 450kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 460kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 471kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 481kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 491kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 501kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 512kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 522kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 532kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 542kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 552kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 563kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 573kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 583kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 593kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 604kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 614kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 624kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 634kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 645kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 655kB 5.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypng\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-cp37-none-any.whl size=67163 sha256=c1c81872ef4feb2859d051cd50d0d4a22cbeced20165503478f230ddbfc68e24\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
            "Successfully built pypng\n",
            "Installing collected packages: pypng\n",
            "Successfully installed pypng-0.0.20\n",
            "Collecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (56.1.0)\n",
            "Installing collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.2\n",
            "Collecting setproctitle\n",
            "  Downloading https://files.pythonhosted.org/packages/97/5c/16a6e69febfbee3f1a1a8c4318d1f054ff4d3ef2a61b233937c316cba06d/setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/de/0c22c6754370ba6b1fa8e53bd6e514d4a41a181125d405a501c215cbdbd6/scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "\u001b[31mERROR: pymc3 3.11.2 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: setproctitle, colorama, scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed colorama-0.4.4 scipy-1.1.0 setproctitle-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_n1EXdL6SQ1",
        "outputId": "f2413bf3-63fc-402d-d22d-cc4c5bceee3f"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da',dest_path='./FlowNet2_checkpoint.pth.tar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da into ./FlowNet2_checkpoint.pth.tar... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyoZWU0s6Un_"
      },
      "source": [
        "# Run the inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrGlYzKfTeVo"
      },
      "source": [
        "### Uploading sample video. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeZL0nbj9Mwk",
        "outputId": "364e0dda-d495-4abf-a3e4-4f43964836bd"
      },
      "source": [
        "mkdir_ifnotexists('./videos')\n",
        "gdd.download_file_from_google_drive(file_id='1DHxE-PakEtAs7IrxUiO0VAIw8Jq5PKMC',dest_path='./videos/ship.mp4')\n",
        "gdd.download_file_from_google_drive(file_id='1V9N5FenOdJyDWKj8DKhuem6iCmVbVzRW',dest_path='./videos/snowplanet.mp4')\n",
        "##gdd.download_file_from_google_drive(file_id='1IW7qO9hDG8VJVnYuJI1ov1pmDkoq3vMC',dest_path='./videos/skyhouse.mp4')\n",
        "gdd.download_file_from_google_drive(file_id='1detmA3HBFp21GrifsLZvN-M4pOL_aPYp',dest_path='./videos/cartooncoaster.mp4')\n",
        "##gdd.download_file_from_google_drive(file_id='1cpbRTupK1OohYsp5qAu83Lkfzmhr9ACz',dest_path='./videos/glowingdance.mp4')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1DHxE-PakEtAs7IrxUiO0VAIw8Jq5PKMC into ./videos/ship.mp4... Done.\n",
            "Downloading 1V9N5FenOdJyDWKj8DKhuem6iCmVbVzRW into ./videos/snowplanet.mp4... Done.\n",
            "Downloading 1detmA3HBFp21GrifsLZvN-M4pOL_aPYp into ./videos/cartooncoaster.mp4... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nh294_TSW2x"
      },
      "source": [
        "# Visualizing flo files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IQiY4VISh0F"
      },
      "source": [
        "### Define show_flow() for visualization.\n",
        " Original Source https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHlGgYpCSkbu"
      },
      "source": [
        "# Source:https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "UNKNOWN_FLOW_THRESH = 1e7\n",
        "def show_flow(filename):\n",
        "    \"\"\"\n",
        "    visualize optical flow map using matplotlib\n",
        "    :param filename: optical flow file\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    flow = read_flow(filename)\n",
        "    img = flow_to_image(flow)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "def read_flow(filename):\n",
        "    \"\"\"\n",
        "    read optical flow from Middlebury .flo file\n",
        "    :param filename: name of the flow file\n",
        "    :return: optical flow data in matrix\n",
        "    \"\"\"\n",
        "    f = open(filename, 'rb')\n",
        "    magic = np.fromfile(f, np.float32, count=1)\n",
        "    data2d = None\n",
        "\n",
        "    if 202021.25 != magic:\n",
        "        print ('Magic number incorrect. Invalid .flo file')\n",
        "    else:\n",
        "        w = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        h = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        #print(\"Reading %d x %d flo file\" % (h, w))\n",
        "        data2d = np.fromfile(f, np.float32, count=2 * w * h)\n",
        "        # reshape data into 3D array (columns, rows, channels)\n",
        "        data2d = np.resize(data2d, (h, w, 2))\n",
        "    f.close()\n",
        "    return data2d\n",
        "\n",
        "def flow_to_image(flow):\n",
        "    \"\"\"\n",
        "    Convert flow into middlebury color code image\n",
        "    :param flow: optical flow map\n",
        "    :return: optical flow image in middlebury color\n",
        "    \"\"\"\n",
        "    u = flow[:, :, 0]\n",
        "    v = flow[:, :, 1]\n",
        "\n",
        "    maxu = -999.\n",
        "    maxv = -999.\n",
        "    minu = 999.\n",
        "    minv = 999.\n",
        "\n",
        "    idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n",
        "    u[idxUnknow] = 0\n",
        "    v[idxUnknow] = 0\n",
        "\n",
        "    maxu = max(maxu, np.max(u))\n",
        "    minu = min(minu, np.min(u))\n",
        "\n",
        "    maxv = max(maxv, np.max(v))\n",
        "    minv = min(minv, np.min(v))\n",
        "\n",
        "    rad = np.sqrt(u ** 2 + v ** 2)\n",
        "    maxrad = max(-1, np.max(rad))\n",
        "\n",
        "    #print( \"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n",
        "\n",
        "    u = u/(maxrad + np.finfo(float).eps)\n",
        "    v = v/(maxrad + np.finfo(float).eps)\n",
        "\n",
        "    img = compute_color(u, v)\n",
        "\n",
        "    idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n",
        "    img[idx] = 0\n",
        "\n",
        "    return np.uint8(img)\n",
        "\n",
        "\n",
        "def compute_color(u, v):\n",
        "    \"\"\"\n",
        "    compute optical flow color map\n",
        "    :param u: optical flow horizontal map\n",
        "    :param v: optical flow vertical map\n",
        "    :return: optical flow in color code\n",
        "    \"\"\"\n",
        "    [h, w] = u.shape\n",
        "    img = np.zeros([h, w, 3])\n",
        "    nanIdx = np.isnan(u) | np.isnan(v)\n",
        "    u[nanIdx] = 0\n",
        "    v[nanIdx] = 0\n",
        "\n",
        "    colorwheel = make_color_wheel()\n",
        "    ncols = np.size(colorwheel, 0)\n",
        "\n",
        "    rad = np.sqrt(u**2+v**2)\n",
        "\n",
        "    a = np.arctan2(-v, -u) / np.pi\n",
        "\n",
        "    fk = (a+1) / 2 * (ncols - 1) + 1\n",
        "\n",
        "    k0 = np.floor(fk).astype(int)\n",
        "\n",
        "    k1 = k0 + 1\n",
        "    k1[k1 == ncols+1] = 1\n",
        "    f = fk - k0\n",
        "\n",
        "    for i in range(0, np.size(colorwheel,1)):\n",
        "        tmp = colorwheel[:, i]\n",
        "        col0 = tmp[k0-1] / 255\n",
        "        col1 = tmp[k1-1] / 255\n",
        "        col = (1-f) * col0 + f * col1\n",
        "\n",
        "        idx = rad <= 1\n",
        "        col[idx] = 1-rad[idx]*(1-col[idx])\n",
        "        notidx = np.logical_not(idx)\n",
        "\n",
        "        col[notidx] *= 0.75\n",
        "        img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def make_color_wheel():\n",
        "    \"\"\"\n",
        "    Generate color wheel according Middlebury color code\n",
        "    :return: Color wheel\n",
        "    \"\"\"\n",
        "    RY = 15\n",
        "    YG = 6\n",
        "    GC = 4\n",
        "    CB = 11\n",
        "    BM = 13\n",
        "    MR = 6\n",
        "\n",
        "    ncols = RY + YG + GC + CB + BM + MR\n",
        "\n",
        "    colorwheel = np.zeros([ncols, 3])\n",
        "\n",
        "    col = 0\n",
        "\n",
        "    # RY\n",
        "    colorwheel[0:RY, 0] = 255\n",
        "    colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n",
        "    col += RY\n",
        "\n",
        "    # YG\n",
        "    colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n",
        "    colorwheel[col:col+YG, 1] = 255\n",
        "    col += YG\n",
        "\n",
        "    # GC\n",
        "    colorwheel[col:col+GC, 1] = 255\n",
        "    colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n",
        "    col += GC\n",
        "\n",
        "    # CB\n",
        "    colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n",
        "    colorwheel[col:col+CB, 2] = 255\n",
        "    col += CB\n",
        "\n",
        "    # BM\n",
        "    colorwheel[col:col+BM, 2] = 255\n",
        "    colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n",
        "    col += + BM\n",
        "\n",
        "    # MR\n",
        "    colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n",
        "    colorwheel[col:col+MR, 0] = 255\n",
        "\n",
        "    return colorwheel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th4dGr4nR7HK"
      },
      "source": [
        "## Optical flow calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_Y4fTLyIGHI"
      },
      "source": [
        "### .flo file to npy array file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw9zgVwVINCY"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "def flo2csv(videoName, lon, lat):\n",
        "\n",
        "  flo_pth='/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "  flos=[flo_pth + f for f in os.listdir(flo_pth)]\n",
        "\n",
        "  flo_npy_pth='/content/gdrive/MyDrive/Video_Rest_Frames/'\n",
        "  mkdir_ifnotexists(flo_npy_pth)\n",
        "  flo_npy_pth='/content/gdrive/MyDrive/Video_Rest_Frames/opticalflow/'\n",
        "  mkdir_ifnotexists(flo_npy_pth)\n",
        "  flo_npy_pth=flo_npy_pth+videoName+'/'\n",
        "  mkdir_ifnotexists(flo_npy_pth)\n",
        "  flo_npy_pth=flo_npy_pth+'horizontal_'+str(lon)+'_vertical_'+str(lat)+'.csv'\n",
        "  if os.path.exists(flo_npy_pth):\n",
        "        return\n",
        "  flos = sorted(flos)\n",
        "  for i in range(len(flos)):\n",
        "    npyfiles = np.array([read_flow(flos[i])])\n",
        "    npyfiles = npyfiles[0]\n",
        "    c = np.sqrt(np.sum(npyfiles*npyfiles, axis=2))\n",
        "    value =  np.matrix.sum(np.matrix(c))/npyfiles.shape[0]/npyfiles.shape[1]\n",
        "    if i == 0:\n",
        "      average_flo =   [value]\n",
        "    else:\n",
        "      average_flo.append(value)\n",
        "    os.remove(flos[i])\n",
        "  DF = pd.DataFrame(average_flo) \n",
        "  DF.to_csv(flo_npy_pth)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0pxTydQbkai"
      },
      "source": [
        "### Calculate optical flow and disparity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DLznyl-SJDU",
        "outputId": "f64a4bcb-56ff-43cd-cfba-5f28b284dd33"
      },
      "source": [
        "from google.colab import files\n",
        "video_pth='/content/flownet2pytorch/videos/'\n",
        "videos=[video_pth + v for v in os.listdir(video_pth)]\n",
        "videonames = [os.path.splitext(os.path.basename(v))[0] for v in os.listdir(video_pth)]\n",
        "print(videonames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['snowplanet', 'cartooncoaster', 'ship']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72UAsgbHW7yX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e98d46-a6e7-4711-9047-f6c9f48a8464"
      },
      "source": [
        "# Clean disparity, output, frames folder\n",
        "import shutil\n",
        "import time\n",
        "import multiprocessing as mp\n",
        "\n",
        "\n",
        "\n",
        "for i in videonames:\n",
        "  print(i)\n",
        "  os.chdir('/content/flownet2pytorch')\n",
        "  if os.path.exists('/content/flownet2pytorch/frames'):\n",
        "    shutil.rmtree(r'/content/flownet2pytorch/frames')\n",
        "  if os.path.exists('/content/flownet2pytorch/output'):\n",
        "    shutil.rmtree(r'/content/flownet2pytorch/output')\n",
        "  for theta in range(-180, 180, 15):\n",
        "    for phi in range(90, -105, -15):\n",
        "      flo_npy_pth='/content/gdrive/MyDrive/Video_Rest_Frames/opticalflow/'\n",
        "      flo_npy_pth=flo_npy_pth+i+'/'\n",
        "      flo_npy_pth=flo_npy_pth+'horizontal_'+str(theta)+'_vertical_'+str(phi)+'.csv'\n",
        "      if os.path.exists(flo_npy_pth):\n",
        "        continue\n",
        "      t= time.time()\n",
        "      print(flo_npy_pth)\n",
        "      perspectiveSotre(theta, phi, i)\n",
        "      print('Convert: '+str(time.time()-t)+'seconds')\n",
        "      mkdir_ifnotexists('./output')\n",
        "      t = time.time()\n",
        "      # Generate .flo files using FlowNet2\n",
        "      !python main.py --inference --model FlowNet2 --save_flow --save ./output --inference_dataset ImagesFromFolder --inference_dataset_root ./frames --resume ./FlowNet2_checkpoint.pth.tar\n",
        "      print('Flo: '+str(time.time()-t)+'seconds')\n",
        "      npy_pth = flo2csv(i, theta, phi)\n",
        "      print('CSV: '+str(time.time()-t)+'seconds')\n",
        "  print('Finished '+i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "snowplanet\n",
            "Finished snowplanet\n",
            "cartooncoaster\n",
            "Finished cartooncoaster\n",
            "ship\n",
            "Finished ship\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze9bLvIZGc79"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}